{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunrise-hurricane",
   "metadata": {},
   "source": [
    "## Set Target Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "chinese-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All files in target_dir will be Unified file name,include directorys.\n",
    "# You should change target_dir string manually .\n",
    "# You should better use absolute directory path .\n",
    "target_dir = \"../EmptyDir/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-african",
   "metadata": {},
   "source": [
    "## Desfine Set and Also Pickle to File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "noted-cinema",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-08T09:40:13.047132Z",
     "iopub.status.busy": "2021-03-08T09:40:13.046948Z",
     "iopub.status.idle": "2021-03-08T09:40:13.049376Z",
     "shell.execute_reply": "2021-03-08T09:40:13.048954Z",
     "shell.execute_reply.started": "2021-03-08T09:40:13.047115Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-newspaper",
   "metadata": {},
   "source": [
    "#### Define Characters Set Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wooden-funds",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-08T09:48:17.061869Z",
     "iopub.status.busy": "2021-03-08T09:48:17.061570Z",
     "iopub.status.idle": "2021-03-08T09:48:17.081133Z",
     "shell.execute_reply": "2021-03-08T09:48:17.080491Z",
     "shell.execute_reply.started": "2021-03-08T09:48:17.061834Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "CharDictionary = collections.OrderedDict()\n",
    "specChar = \"_\"\n",
    "CharDictionary = {\n",
    "    \"\\r\": specChar,\n",
    "    \"\\n\": specChar,\n",
    "    \"?\": specChar,\n",
    "    \",\": specChar,\n",
    "    \"!\": specChar,\n",
    "    \":\": specChar,\n",
    "    \"&\": specChar,\n",
    "    \"@\": specChar,\n",
    "    \"Â·\": specChar,\n",
    "    \"\\`\": specChar,\n",
    "    \" \": specChar,\n",
    "    \"(\": specChar,\n",
    "    \")\": specChar,\n",
    "    \"'\": specChar,\n",
    "    \"+\": specChar,\n",
    "    \"-\": specChar,\n",
    "    \"=\": specChar,\n",
    "    \"|\": specChar,\n",
    "    \"[\": specChar,\n",
    "    \"]\": specChar,\n",
    "    \"{\": specChar,\n",
    "    \"}\": specChar,\n",
    "    \"Â»\": specChar,\n",
    "    \"Â«\": specChar,\n",
    "    \"\\\"\": specChar,\n",
    "    \"*\": specChar,\n",
    "    \"#\": specChar,\n",
    "    \"Â®\": specChar,\n",
    "    \"â€¦\": specChar,\n",
    "    \"â€œ\": specChar,\n",
    "    \"â€\": specChar,\n",
    "    \".\": specChar,\n",
    "    \"â€¢\": specChar,\n",
    "    \"ï¼Œ\": specChar,\n",
    "    \"â€“\": specChar,\n",
    "    \"â€”\": specChar,\n",
    "#     \"ä¸€\": specChar,\n",
    "    \"ã€\": specChar,\n",
    "    \"ï¼ˆ\": specChar,\n",
    "    \"ï¼‰\": specChar,\n",
    "    \"ã€Š\": specChar,\n",
    "    \"ã€‹\": specChar,\n",
    "    \">\": specChar,\n",
    "    \"ã€\": specChar,\n",
    "    \"ã€‘\": specChar,\n",
    "    \"ã€Œ\": specChar,\n",
    "    \"ã€\": specChar,\n",
    "    \"ï½œ\": specChar,\n",
    "    \"ï¼š\": specChar,\n",
    "    \"ï¼›\": specChar,\n",
    "    \"ï¼Ÿ\": specChar,\n",
    "    \"ï¼\": specChar,\n",
    "    \"ðŸš€\": specChar,\n",
    "    \"ðŸš´\": specChar,\n",
    "    \"ðŸŒ\": specChar,\n",
    "    \"ðŸ¾\": specChar,\n",
    "    \"%2F\": specChar,\n",
    "    \"____\": specChar,\n",
    "    \"___\": specChar,\n",
    "    \"__\": specChar,\n",
    "    \"._\": specChar,\n",
    "    \"Whatâ€™s\": \"What_is\",\n",
    "    \"whatâ€™s\": \"what_is\"\n",
    "}\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "fname = \"CharDictionary_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"CharDictionary.pkl\")\n",
    "\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(CharDictionary, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-tumor",
   "metadata": {},
   "source": [
    "#### Define Terminology Set Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adopted-intranet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T10:43:14.254920Z",
     "iopub.status.busy": "2021-03-02T10:43:14.254292Z",
     "iopub.status.idle": "2021-03-02T10:43:14.282950Z",
     "shell.execute_reply": "2021-03-02T10:43:14.281958Z",
     "shell.execute_reply.started": "2021-03-02T10:43:14.254835Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TerminologyDictionary = {\n",
    "    #     \"apple\": \"Apple\",\n",
    "    \"api\": \"API\",\n",
    "    \"atm\": \"ATM\",\n",
    "    \"cypress\": \"CYPRESS\",\n",
    "    \"dji\": \"DJI\",\n",
    "    #     \"google\": \"Google\",\n",
    "    \"i2c\": \"I2C\",\n",
    "    \"kicad\": \"KiCAD\",\n",
    "    \"mosfet\": \"MOSFET\",\n",
    "    \"mux\": \"MUX\",\n",
    "    \"nltk\": \"NLTK\",\n",
    "    \"pcb\": \"PCB\",\n",
    "    \"pcie\": \"PCIe\",\n",
    "    \"psoc\": \"PSoC\",\n",
    "    \"rohs\": \"ROHS\",\n",
    "    \"spi\": \"SPI\",\n",
    "    \"ti\": \"TI\",\n",
    "    \"usb\": \"USB\",\n",
    "    \"vishay\": \"VISHAY\",\n",
    "}\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "fname = \"TerminologyDictionary_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"TerminologyDictionary.pkl\")\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(TerminologyDictionary, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-attachment",
   "metadata": {},
   "source": [
    "#### Define Ignored Directory Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "religious-variety",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T11:17:31.269301Z",
     "iopub.status.busy": "2021-03-02T11:17:31.269003Z",
     "iopub.status.idle": "2021-03-02T11:17:31.286894Z",
     "shell.execute_reply": "2021-03-02T11:17:31.285873Z",
     "shell.execute_reply.started": "2021-03-02T11:17:31.269264Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IgnoredDirectoryKeyList = [\".git\", \".xcodeproj\", \".cydsn\", \".cywrk\"]\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "fname = \"IgnoredDirectoryKeyList_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"IgnoredDirectoryKeyList.pkl\")\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(IgnoredDirectoryKeyList, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-sustainability",
   "metadata": {},
   "source": [
    "#### Get Words Set and Convert to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hidden-macintosh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T10:43:27.616964Z",
     "iopub.status.busy": "2021-03-02T10:43:27.616741Z",
     "iopub.status.idle": "2021-03-02T10:43:28.481241Z",
     "shell.execute_reply": "2021-03-02T10:43:28.480294Z",
     "shell.execute_reply.started": "2021-03-02T10:43:27.616937Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "LowerCaseWordSet = set(list(map(lambda x: x.lower(), words.words())))\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "with open(\n",
    "        os.path.join(\n",
    "            data_path,\n",
    "            \"NLTK_corpus_words_\" + datetime.now().strftime(\"%Y%m%d\") + \".pkl\"),\n",
    "        \"wb\") as fhand:\n",
    "    pickle.dump(words.words(), fhand)\n",
    "\n",
    "fname = \"LowerCaseWordSet_\" + datetime.now().strftime(\"%Y%m%d\" + \".pkl\")\n",
    "fpath = os.path.join(data_path, fname)\n",
    "lnkpath = os.path.join(data_path, \"LowerCaseWordSet.pkl\")\n",
    "with open(fpath, \"wb\") as fhand:\n",
    "    pickle.dump(LowerCaseWordSet, fhand)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if os.path.exists(lnkpath):\n",
    "    os.remove(lnkpath)\n",
    "createLink = subprocess.Popen([\"ln\", \"-s\", fname, lnkpath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-projection",
   "metadata": {},
   "source": [
    "---\n",
    "## Jupyter Notebook Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-career",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "billion-triumph",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replaceChar(charDict={}, tgtString=\"\"):\n",
    "    assert charDict\n",
    "    assert tgtString\n",
    "    print(tgtString)\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    for key, value in charDict.items():\n",
    "        if key in root:\n",
    "            root = root.replace(key, value)\n",
    "            print(\"---%s\" % root + ext)\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def processHeadTailChar(tgtString=\"\"):\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    if root.startswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[1:])\n",
    "    if root.endswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[0:-1])\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def processTerminology(termDictionary={}, tgtString=\"\"):\n",
    "    assert termDictionary\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in termDictionary.keys():\n",
    "            newWordList.append(termDictionary[word.lower()])\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "    return specChar.join(newWordList) + ext\n",
    "\n",
    "\n",
    "def titlelize(tgtString=\"\"):\n",
    "    assert tgtString\n",
    "    import os\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    return root.title() + ext\n",
    "\n",
    "\n",
    "def processWord(wordSet=set(), tgtString=\"\"):\n",
    "    assert wordSet\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    import os\n",
    "    import string\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in wordSet:\n",
    "            newWordList.append(string.capwords(word))\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "\n",
    "    return specChar.join(newWordList) + ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-southeast",
   "metadata": {},
   "source": [
    "### Processing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "wooden-chicago",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for subdir, dirs, files in os.walk(target_dir):\n",
    "    for file in files:\n",
    "        oldNamePath = os.path.join(subdir, file)\n",
    "        #         newName = \"\".join(file.split())\n",
    "        newName = file\n",
    "        # replace characters by defined Dictionary\n",
    "        newName = replaceChar(charDict=CharDictionary, tgtString=newName)\n",
    "        # process Head and Tail character exclude file name extension\n",
    "        newName = processHeadTailChar(tgtString=newName)\n",
    "        # Capitalize\n",
    "        #         newName = newName.capitalize()\n",
    "        # Titlelize File Name\n",
    "        #         newName = titlelize(tgtString=newName)\n",
    "        # Capwords only when word in wordsSet\n",
    "        newName = processWord(wordSet=LowerCaseWordSet, tgtString=newName)\n",
    "        # Pretty Terminology\n",
    "        newName = processTerminology(termDictionary=TerminologyDictionary,\n",
    "                                     tgtString=newName)\n",
    "        # Create full path\n",
    "        newNamePath = os.path.join(subdir, newName)\n",
    "        # rename file name\n",
    "        os.rename(oldNamePath, newNamePath)\n",
    "        print(\"==>%s\" % newName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-northeast",
   "metadata": {},
   "source": [
    "---\n",
    "## Standalone Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "julian-paintball",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-08T09:41:06.374620Z",
     "iopub.status.busy": "2021-03-08T09:41:06.374401Z",
     "iopub.status.idle": "2021-03-08T09:41:06.380586Z",
     "shell.execute_reply": "2021-03-08T09:41:06.380105Z",
     "shell.execute_reply.started": "2021-03-08T09:41:06.374591Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting UFn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile UFn.py\n",
    "\n",
    "import hashlib\n",
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import string\n",
    "import click\n",
    "\n",
    "\n",
    "class FileNameLog:\n",
    "\n",
    "    def __init__(self, filePath=\"\", md5Value=\"\"):\n",
    "        if not md5Value:\n",
    "            assert os.path.exists(filePath)\n",
    "            with open(filePath, \"rb\") as fhand:\n",
    "                data = fhand.read()\n",
    "                md5Value = hashlib.md5(data).hexdigest()\n",
    "        self.md5Value = str(md5Value)\n",
    "        self._currentName = os.path.basename(filePath)\n",
    "        self._nameRecord = collections.OrderedDict()\n",
    "\n",
    "    def changeFileName(self, newFileName=\"\", stamp=\"\"):\n",
    "        assert newFileName\n",
    "        if not stamp:\n",
    "            stamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "        self._nameRecord[stamp] = self._currentName\n",
    "        self._currentName = newFileName\n",
    "\n",
    "    def getFileNameHistory(self):\n",
    "        return {\n",
    "            self.md5Value: {\n",
    "                \"currentName\": self._currentName,\n",
    "                \"nameRecord\": self._nameRecord\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "def createFileNameLog(filePath=\"\", md5Value=\"\"):\n",
    "    global globalHistoryRecordPath\n",
    "    if not md5Value:\n",
    "        assert os.path.isfile(filePath)\n",
    "        with open(filePath, \"rb\") as fhand:\n",
    "            data = fhand.read()\n",
    "            md5Value = hashlib.md5(data).hexdigest()\n",
    "    fRecordPath = os.path.join(globalHistoryRecordPath,\n",
    "                               str(md5Value) + \"_HRd.pkl\")\n",
    "    if os.path.isfile(fRecordPath):\n",
    "        with open(fRecordPath, \"rb\") as fhand:\n",
    "            rd = pickle.load(fhand)\n",
    "        return rd\n",
    "    else:\n",
    "        assert os.path.isfile(filePath)\n",
    "        return FileNameLog(filePath)\n",
    "\n",
    "\n",
    "def isHiddenFile(path):\n",
    "    if os.name == \"nt\":\n",
    "        import win32api, win32con\n",
    "    if os.name == \"nt\":\n",
    "        attribute = win32api.GetFileAttributes(path)\n",
    "        return attribute & (win32con.FILE_ATTRIBUTE_HIDDEN |\n",
    "                            win32con.FILE_ATTRIBUTE_SYSTEM)\n",
    "    else:\n",
    "        return os.path.basename(path).startswith('.')  #linux-osx\n",
    "\n",
    "\n",
    "def replaceChar(charDict={}, tgtString=\"\"):\n",
    "    global globalFileNameHistoryRecordList\n",
    "    assert charDict\n",
    "    assert tgtString\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    for key, value in charDict.items():\n",
    "        if key in root:\n",
    "            root = root.replace(key, value)\n",
    "            if not globalParameterDictionary[\"simple\"]:\n",
    "                globalFileNameHistoryRecordList.append(root + ext)\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def processHeadTailChar(tgtString=\"\"):\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    if root.startswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[1:])\n",
    "    if root.endswith(specChar):\n",
    "        root = specChar.join(root.split(specChar)[0:-1])\n",
    "    return root + ext\n",
    "\n",
    "\n",
    "def processTerminology(termDictionary={}, tgtString=\"\"):\n",
    "    assert termDictionary\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in termDictionary.keys():\n",
    "            newWordList.append(termDictionary[word.lower()])\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "    return specChar.join(newWordList) + ext\n",
    "\n",
    "\n",
    "def processWord(wordSet=set(), tgtString=\"\"):\n",
    "    assert wordSet\n",
    "    assert tgtString\n",
    "    specChar = \"_\"\n",
    "    root, ext = os.path.splitext(tgtString)\n",
    "    wordList = root.split(specChar)\n",
    "    newWordList = []\n",
    "    for word in wordList:\n",
    "        if word.lower() in wordSet:\n",
    "            newWordList.append(string.capwords(word))\n",
    "        else:\n",
    "            newWordList.append(word)\n",
    "\n",
    "    return specChar.join(newWordList) + ext\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"--path\",\n",
    "              prompt=\"target path\",\n",
    "              help=\"Recursively traverse path,All files will be changed name.\")\n",
    "@click.option(\"--exclude\", default=\"\", help=\"Exclude all files in exclude path\")\n",
    "@click.option(\"--dry\",\n",
    "              default=True,\n",
    "              type=bool,\n",
    "              help=\"If dry is True will not change file name.Default is True.\")\n",
    "@click.option(\n",
    "    \"--simple\",\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help=\"If simple is True Only print changed file name.Default is True.\")\n",
    "def ufn(path, exclude, dry, simple):\n",
    "    global globalDataPath\n",
    "    global globalParameterDictionary\n",
    "    global globalFileNameHistoryRecordList\n",
    "    \"\"\"Files in PATH will be changed file names unified.\"\"\"\n",
    "    globalParameterDictionary[\"path\"] = path\n",
    "    globalParameterDictionary[\"exclude\"] = exclude\n",
    "    globalParameterDictionary[\"dry\"] = dry\n",
    "    globalParameterDictionary[\"simple\"] = simple\n",
    "    import os\n",
    "    if not os.path.isdir(globalParameterDictionary[\"path\"]):\n",
    "        click.echo(\"%s is not valid path.\")\n",
    "        return -1\n",
    "\n",
    "    with open(os.path.join(globalDataPath, \"CharDictionary.pkl\"),\n",
    "              \"rb\") as fhand:\n",
    "        CharDictionary = pickle.load(fhand)\n",
    "    with open(os.path.join(globalDataPath, \"TerminologyDictionary.pkl\"),\n",
    "              \"rb\") as fhand:\n",
    "        TerminologyDictionary = pickle.load(fhand)\n",
    "    with open(os.path.join(globalDataPath, \"LowerCaseWordSet.pkl\"),\n",
    "              \"rb\") as fhand:\n",
    "        LowerCaseWordSet = pickle.load(fhand)\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            #             if not os.path.isfile(file):\n",
    "            #                 continue\n",
    "            globalFileNameHistoryRecordList = []\n",
    "            oldNamePath = os.path.join(subdir, file)\n",
    "            if isHiddenFile(oldNamePath):\n",
    "                continue\n",
    "            newName = file\n",
    "            # replace characters by defined Dictionary\n",
    "            newName = replaceChar(charDict=CharDictionary, tgtString=newName)\n",
    "            # process Head and Tail character exclude file name extension\n",
    "            newName = processHeadTailChar(tgtString=newName)\n",
    "            # Capwords only when word in wordsSet\n",
    "            newName = processWord(wordSet=LowerCaseWordSet, tgtString=newName)\n",
    "            # Pretty Terminology\n",
    "            newName = processTerminology(termDictionary=TerminologyDictionary,\n",
    "                                         tgtString=newName)\n",
    "            # Capitalize The First Letter\n",
    "            newName = newName[0].upper() + newName[1:]\n",
    "            # Create full path\n",
    "            newNamePath = os.path.join(subdir, newName)\n",
    "            if not globalParameterDictionary[\"dry\"]:\n",
    "                # Create Or Update File Name Change Record and Save to File\n",
    "                # then rename file name\n",
    "                if newName != file:\n",
    "                    fileHistoryRecord = createFileNameLog(filePath=oldNamePath)\n",
    "                    with open(\n",
    "                            os.path.join(\n",
    "                                globalHistoryRecordPath,\n",
    "                                str(fileHistoryRecord.md5Value) + \"_HRd.pkl\"),\n",
    "                            \"wb\") as fhand:\n",
    "                        fileHistoryRecord.changeFileName(newFileName=newName)\n",
    "                        pickle.dump(fileHistoryRecord, fhand)\n",
    "                    os.rename(oldNamePath, newNamePath)\n",
    "\n",
    "            if (not globalParameterDictionary[\"simple\"]) or (newName != file):\n",
    "                click.echo(\"   %s\" % file)\n",
    "                for fName in globalFileNameHistoryRecordList:\n",
    "                    click.echo(\"---%s\" % fName)\n",
    "                click.echo(\"==>%s\" % newName)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scriptDirPath = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "    globalDataPath = os.path.join(scriptDirPath, \"data\")\n",
    "    globalHistoryRecordPath = os.path.join(globalDataPath, \"hRdDir\")\n",
    "\n",
    "    globalParameterDictionary = {}\n",
    "    globalFileNameHistoryRecordList = []\n",
    "\n",
    "    ufn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-chair",
   "metadata": {},
   "source": [
    "---\n",
    "## Roadmap\n",
    "\n",
    "* colorfull print the difference OldFileName and NewFileName\n",
    "* support undo operation \n",
    "* support set depth\n",
    "* support set ignore directory or files\n",
    "* pretty ShortTerm,such as ATM,ROHS,PCB,...\n",
    "* personalize file name ,such as capatilize every word,...\n",
    "* search all ipynb or python file name and auto correction ...\n",
    "* reserve original file name as link\n",
    "* ensure First Char in Alphabet and Capitalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-school",
   "metadata": {},
   "source": [
    "## Others ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-sheet",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "divine-convertible",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T09:59:57.342584Z",
     "iopub.status.busy": "2021-03-05T09:59:57.342030Z",
     "iopub.status.idle": "2021-03-05T09:59:57.345408Z",
     "shell.execute_reply": "2021-03-05T09:59:57.344700Z",
     "shell.execute_reply.started": "2021-03-05T09:59:57.342560Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# file_list = []\n",
    "# ignore_dir_path_list = []\n",
    "# for subdir, dirs, files in os.walk(\"/home/HoM/Downloads/\"):\n",
    "#     for file in files:\n",
    "#         file_list.append(os.path.join(subdir, file))\n",
    "\n",
    "#     break_flag = False\n",
    "#     for ign_dir_key in IgnoredDirectoryKeyList:\n",
    "#         if break_flag:\n",
    "#             break\n",
    "#         for d in dirs:\n",
    "#             if d.endswith(ign_dir_key):\n",
    "#                 ignore_dir_path_list.append(\n",
    "#                     subdir if subdir.endswith(\"/\") else subdir + \"/\")\n",
    "#                 break_flag = True\n",
    "#                 break\n",
    "# for ig_dir in ignore_dir_path_list:\n",
    "#     print(ig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complex-parallel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-05T09:59:43.943451Z",
     "iopub.status.busy": "2021-03-05T09:59:43.942541Z",
     "iopub.status.idle": "2021-03-05T09:59:43.951219Z",
     "shell.execute_reply": "2021-03-05T09:59:43.948952Z",
     "shell.execute_reply.started": "2021-03-05T09:59:43.943341Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ignored_file_path_list = []\n",
    "# for f in file_list:\n",
    "#     for ig_dir in ignore_dir_path_list:\n",
    "#         if f.startswith(ig_dir):\n",
    "#             ignored_file_path_list.append(f)\n",
    "#             break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
